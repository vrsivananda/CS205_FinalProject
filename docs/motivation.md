## Problem Description & Motivation

One challenge of the twenty-first century computing paradigm is the acceleration and capture of increasing amounts of data, at more fine-grained resolutions. The financial industry provides one salient source of this phenomenon: as computing power and infrastructure scale, it is possible to not only make predictions for trading based days or weeks in the future, but rather minutes or seconds. In the world of high-frequency trading, low latency is paramount, enabling algorithmic traders to quickly arbitrage prices in order to beat bid-ask spreads (Picardo, 2019). While high frequency traders often rely on algorithms to receive signals from a market and act on it before third parties are able to, new methods for time-series prediction have also arisen, particularly in the case of recurrent neural networks. In this project, we seek to unite these two themes, developing a pipeline to (1) process scalable quantities of high-frequency financial transaction data, (2) utilize multiple nodes and GPUs to speed up training of sequential models which are notoriously difficult to parallelize, and (3) serve predictions based on the trained model in a distributed manner.

## Pipeline Overview

Our pipeline breaks down into the three phases described above. All testing done for these phases is described below, though could, in principle be combined into a single phase. However, each of these steps can be discretized. This is an important aspect when considering cost and the computational resources necessary to sustain our models, as users may wish to divide the resources necessary, either for time purposes or in order to reduce the financial constraints of scraping the data and running the models together.

1. **[Data Processing](https://github.com/vrsivananda/CS205_FinalProject/blob/master/docs/processing.md)**:  The data processing pipeline retrieves the data from the `yfinance` API, a Python-based framework which accesses minute-by-minute trade data for all 500 stocks of the S&P500 from Yahoo Finance. Using multiple-thread and multiple-core processing, this pipeline is sped up significantly.
2. **[Model Training](https://github.com/vrsivananda/CS205_FinalProject/blob/master/docs/model_training.md)**: [LINK!] To model this high-frequency sequential data, we create sequences of 60 minutes each, and feed these sequences into a version of a recurrent neural network known as a LSTM, or Long Short-Term Memory. These models, which exploit the sequential nature of the data, are difficult to parallelize. Thus, we implement two strategies: first, we use accelerated computing on a GPU to speed up matrix-multiplication, and second we orchestrate (a) multiple GPUs on a single node, and (b) up to four GPUs across multiple nodes. As discussed in the Model Training section, our code and framework are also scalable to the multi-GPU, multi-node case.
3. **[Prediction](https://github.com/vrsivananda/CS205_FinalProject/blob/master/docs/prediction.md)**: Once the model has been trained, the next logical step is to serve predictions. We do so in a streamed manner. That is, each minute, we take new prices and volume for some number of stocks and serve predictions of the 5-minute ahead price, each minute.

## Big Compute & Big Data

### Big Compute

Our LSTM models are trained via the backpropagation through time algorithm, a standard algorithm for training highly complex neural networks (Rumelhart, Hinton, and Williams, 1986; Werbos, 1990). This algorithm works by computing the partial gradients of the loss function of our model, and subsequently applying the chain rule to "propagate" this gradient to each weight. Because of this application of the chain rule, backpropagation can be viewed as a series of many matrix multiplications. Moreover, we train the model with gradient descent, an iterative method which requires passing many training samples to the model to update the model weights (explained in more detail [here](LINK!)). Thus, there are two opportunities for parallel computation:

- *Matrix multiplication*: Large matrix multiplications are well-suited for GPU computation due to the lack of computational complexity in computation, but many floating point operations required. Thus, each backpropagation pass can be efficiently sped up by use of GPU computing.
- *Training batches*: LSTMs are inherently sequential models, requiring that each sequence be fed through the model in an ordered way. While many of the computations can be sped up the GPU, this bottleneck remains compared to neural networks without the sequential nature, such as convolutional neural networks. To overcome this, we parallelize the training process across multiple GPUs and multiple nodes. This technique effectively increases the batch size of the gradient updates. Using the Ring Reduce algorithm, we are able to achieve comparable accuracy while significantly speeding up the process.

Additionally, our our data processing is a highly parallel process and an example of High-Throughput Computing. Because we retrieve our data from the `yfinance` API, we are limited by the I/O structures and overheads associated with the API. In particular, while the API can use multiple threads for improving I/O performance, this is still bound to a single core. Using the `multiprocessing` module of Python, which mimics a shared-memory, multiple-core processing technique (though does not implement true shared-memory processing), we are able to achieve substantially more efficient data processing.

### Big Data

By its very nature, high-resolution financial data generates significant quantities of data each minute. Because of this, we use big-data techniques to (1) create a streaming application that can run continuously, and (2) parallelize processing of the stream data to efficiently serve predictions. Because of the short time-frame of our prediction problem, making predictions in near-real time is highly important, and parallelization of the data improves scalability.

## Sources

- Rumelhart, David, Geoffrey Hinton, and Ronald Williams, "Learning representations by back-propagating errors," *Nature* 323, October 1986. 
- Werbos, Paul, "Backpropagation Through Time: What It Does and How to Do It," *Proceedings of the IEEE* 78, no. 10, October 1990.
- Picardo, Elvis, "Understanding High-Frequency Trading Terminology," *Investopedia*, May 30, 2019. 