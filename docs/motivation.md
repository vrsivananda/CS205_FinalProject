## Problem Description & Motivation

One challenge of the twenty-first century computing paradigm is the acceleration and capture of increasing amounts of data, at more fine-grained resolutions. The financial industry provides one salient source of this phenomenon: as computing power and infrastructure scale, it is possible to not only make predictions for trading based days or weeks in the future, but rather minutes or seconds. In the world of high-frequency trading, low latency is paramount, enabling algorithmic traders to quickly arbitrage prices in order to beat bid-ask spreads (Picardo, 2019). While high frequency traders often rely on algorithms to receive signals from a market and act on it before third parties are able to, new methods for time-series prediction have also arisen, particularly in the case of recurrent neural networks. In this project, we seek to unite these two themes, developing a pipeline to (1) process scalable quantities of high-frequency financial transaction data, (2) utilize multiple nodes and GPUs to speed up training of sequential models which are notoriously difficult to parallelize, and (3) serve predictions based on the trained model in a distributed manner.

## Pipeline Overview

Our pipeline breaks down into the three phases described above. All testing done for these phases is described below, though could, in principle be combined into a single phase. However, each of these steps can be discretized. This is an important aspect when considering cost and the computational resources necessary to sustain our models, as users may wish to divide the resources necessary, either for time purposes or in order to reduce the financial constraints of scraping the data and running the models together.

1. **[Data Processing](https://github.com/vrsivananda/CS205_FinalProject/blob/master/docs/processing.md)**:  The data processing pipeline retrieves the data from the `yfinance` API, a Python-based framework which accesses minute-by-minute trade data for all 500 stocks of the S&P500 from Yahoo Finance. Using multiple-thread and multiple-core processing, this pipeline is sped up significantly.
2. **[Model Training](https://github.com/vrsivananda/CS205_FinalProject/blob/master/docs/model_training.md)**: To model this high-frequency sequential data, we create sequences of 60 minutes each, and feed these sequences into a version of a recurrent neural network known as a LSTM, or Long Short-Term Memory. These models, which exploit the sequential nature of the data, are difficult to parallelize. Thus, we implement two strategies: first, we use accelerated computing on a GPU to speed up matrix-multiplication, and second we orchestrate (a) multiple GPUs on a single node, and (b) up to four GPUs across multiple nodes. As discussed in the Model Training section, our code and framework are also scalable to the multi-GPU, multi-node case.
3. **[Prediction](https://github.com/vrsivananda/CS205_FinalProject/blob/master/docs/prediction.md)**: Once the model has been trained, the next logical step is to serve predictions. We do so in a streamed manner. That is, each minute, we take new prices and volume for some number of stocks and serve predictions of the 5-minute ahead price, each minute.

## Big Compute & Big Data

### Big Compute

Our LSTM models are trained via the backpropagation through time algorithm, a standard algorithm for training highly complex neural networks (Rumelhart, Hinton, and Williams, 1986; Werbos, 1990). This algorithm works by computing the partial gradients of the loss function of our model, and subsequently applying the chain rule to "propagate" this gradient to each weight. Because of this application of the chain rule, backpropagation can be viewed as a series of many matrix multiplications. Moreover, we train the model with gradient descent, an iterative method which requires passing many training samples to the model to update the model weights (explained in more detail [here](LINK!)). Thus, there are two opportunities for parallel computation:

- *Matrix multiplication*: Large matrix multiplications are well-suited for GPU computation due to the lack of computational complexity in computation, but many floating point operations required. Thus, each backpropagation pass can be efficiently sped up by use of GPU computing.
- *Training batches*: LSTMs are inherently sequential models, requiring that each sequence be fed through the model in an ordered way. While many of the computations can be sped up the GPU, this bottleneck remains compared to neural networks without the sequential nature, such as convolutional neural networks. To overcome this, we parallelize the training process across multiple GPUs and multiple nodes. This technique effectively increases the batch size of the gradient updates. Using the Ring Reduce algorithm, we are able to achieve comparable accuracy while significantly speeding up the process.

Additionally, our our data processing is a highly parallel process and an example of High-Throughput Computing. Because we retrieve our data from the `yfinance` API, we are limited by the I/O structures and overheads associated with the API. In particular, while the API can use multiple threads for improving I/O performance, this is still bound to a single core. Using the `multiprocessing` module of Python, which mimics a shared-memory, multiple-core processing technique (though does not implement true shared-memory processing), we are able to achieve substantially more efficient data processing.

### Big Data

By its very nature, high-resolution financial data generates significant quantities of data each minute. Because of this, we use big-data techniques to (1) create a streaming application that can run continuously, and (2) parallelize processing of the stream data to efficiently serve predictions. Because of the short time-frame of our prediction problem, making predictions in near-real time is highly important, and parallelization of the data improves scalability.



## Existing Work

Our project relates to two separate areas of literature. First, LSTM models have gained popularity for modeling time series data, including high-resolution financial data. We describe these connections more deeply in [Phase II: Model Training](). As an overview, Fisher and Krauss (2017) demonstrate the utility of deep learning methods in financial time series. More recently, Ghosh et al. (2020) and Lanbouri and Achchab (2020) consider LSTMs for high-frequency financial time series. Indeed, our work compares to the results from the latter, which are the most closely related. The authors in that work report RMSE on normalized S&P500 prices of 0.0046. We follow a similar approach, though consider nearly all 505 stocks of the S&P500. Predicting on individual stocks, our hold-out-set error is approximately 0.007 to 0.013. We report a range of outcomes due to the multiple parallel runs of our model. Additionally, we would like to highlight that the focus of our project is parallelism, and further model tuning would likely yield more optimal results.

On the parallelization front, our model training approach follows a similar theoretical approach to Goyal et al. (2018) and Jia et al. (2018), who reduce the training time for ImageNet from 29 hours to one hour and four minutes, respectively. In both cases, such large degrees of parallelism are demonstrated for convolutional neural networks -- we seek to extend their methodology in a proof-of-concept to LSTMs as well. Unfortunately, in our case, we are unable to replicate the those authors' hardware, where they used 236 and 2048 GPUs, respectively.

## Sources

- Fischer, Thomas and Christopher Krauss. 2017. "Deep learning with long short-term memory networks for financial market predictions." *FAU Discussion Papers in Economics No. 11/2017*, Friedrich-Alexander-Universität Erlangen-Nürnberg, Institute for Economics, Nürnberg, May 2017.
- Ghosh, Pushpendu, Ariel Neufeld, and Jajati Keshari Sahoo. 2020. "Forecasting directional movements of stock prices for intraday trading using LSTM and random forests." Working paper, 2004.10178, *arXiv*. Available athttps://arxiv.org/abs/2004.10178.
- Goyal, Priya, Piotr Dollar, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, Kaiming He. 2018. "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour." *arXiv*. Available at, https://arxiv.org/abs/1706.02677.
- Jia. Xianyan, Shutao Song, Wei He, Yangzihao Wang, Haidong Rong, Feihu Zhou, Liqiang Xie, Zhenyu Guo, Yuanzhou Yang, Liwei Yu, Tiegang Chen, Guangxiao Hu, Shaohuai Shi, Xiaowen Chu. "Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes." *arXiv*. Available at https://arxiv.org/abs/1807.11205.
- Rumelhart, David, Geoffrey Hinton, and Ronald Williams, "Learning representations by back-propagating errors," *Nature* 323, October 1986. 
- Werbos, Paul, "Backpropagation Through Time: What It Does and How to Do It," *Proceedings of the IEEE* 78, no. 10, October 1990.
- Picardo, Elvis, "Understanding High-Frequency Trading Terminology," *Investopedia*, May 30, 2019. 